@article{hamzeh2021review,
  title={A review of detection and removal of raindrops in automotive vision systems},
  author={Hamzeh, Yazan and Rawashdeh, Samir A},
  journal={Journal of imaging},
  volume={7},
  number={3},
  pages={52},
  year={2021},
  publisher={MDPI}
}

@INPROCEEDINGS{1315077,
  author={Garg, K. and Nayar, S.K.},
  booktitle={Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.}, 
  title={Detection and removal of rain from videos}, 
  year={2004},
  volume={1},
  number={},
  pages={I-I},
  keywords={Rain;Visual effects;Photometry;Cameras;Image analysis;Layout;Video surveillance;Navigation;Motion pictures;Indexing},
  doi={10.1109/CVPR.2004.1315077}}

@InProceedings{You_2013_CVPR,
author = {You, Shaodi and Tan, Robby T. and Kawakami, Rei and Ikeuchi, Katsushi},
title = {Adherent Raindrop Detection and Removal in Video},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2013}
}

@INPROCEEDINGS{6738189,
  author={Kim, Jin-Hwan and Lee, Chul and Sim, Jae-Young and Kim, Chang-Su},
  booktitle={2013 IEEE International Conference on Image Processing}, 
  title={Single-image deraining using an adaptive nonlocal means filter}, 
  year={2013},
  volume={},
  number={},
  pages={914-917},
  keywords={Rain;Image color analysis;Kernel;Shape;Vectors;Image restoration;Clustering algorithms;Image enhancement;deraining;rain streak removal;nonlocal means filter;kernel regression},
  doi={10.1109/ICIP.2013.6738189}}


@INPROCEEDINGS{5946766,
  author={Fu, Yu-Hsiang and Kang, Li-Wei and Lin, Chia-Wen and Hsu, Chiou-Ting},
  booktitle={2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Single-frame-based rain removal via image decomposition}, 
  year={2011},
  volume={},
  number={},
  pages={1453-1456},
  keywords={Rain;Dictionaries;Image decomposition;Hafnium;Encoding;Training;Matching pursuit algorithms;Rain removal;sparse coding;dictionary learning;image decomposition;morphological component analysis (MCA)},
  doi={10.1109/ICASSP.2011.5946766}}


@article{SHAO2021265,
title = {Selective generative adversarial network for raindrop removal from a single image},
journal = {Neurocomputing},
volume = {426},
pages = {265-273},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.06.134},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220315861},
author = {Mingwen Shao and Le Li and Hong Wang and Deyu Meng},
keywords = {Generative adversarial network, Raindrops removal, Skip connection, Self-attention mechanism},
abstract = {The removal of raindrops from a single image is still challenging because of the diversity and density of raindrops existing in the rainy image. Moreover, the colors of raindrops are constantly changing with the background which also makes the raindrops cannot be well removed by using the current methods. In this paper, we tackle these limitations by combining the raindrops shape features with the background structure features to guide the network to accurately remove raindrops. Specifically, we propose a selective skip connection GAN (SSCGAN) combining the selective skip connection and self-attention mechanism to restoring the clean image from a raindrop degraded one. Our main idea is selectively transmitting the information of raindrops to the decoder through Gated Recurrent Units (GRU) to better generate a clean image. During the training, the selective skip connection model (SSCM) extract raindrops binary mask from the rainy image and eliminate the interference of background noise. Simultaneously, we use self-attention blocks (SABs) to make the generator network pay more attention to global structure features of the rainy image and conversely correct the raindrops binary mask. Experiments show that our method has better performance than previous methods.}
}

@INPROCEEDINGS{8793486,
  author={Porav, Horia and Bruls, Tom and Newman, Paul},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)}, 
  title={I Can See Clearly Now: Image Restoration via De-Raining}, 
  year={2019},
  volume={},
  number={},
  pages={7087-7093},
  keywords={Rain;Image segmentation;Lenses;Task analysis;Computational modeling;Roads;Generators},
  doi={10.1109/ICRA.2019.8793486}}

@InProceedings{Chen_2023_CVPR,
    author    = {Chen, Xiang and Li, Hao and Li, Mingqiang and Pan, Jinshan},
    title     = {Learning a Sparse Transformer Network for Effective Image Deraining},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {5896-5905}
}


@INPROCEEDINGS{7435707,
  author={Kanthan, M. Ramesh and Sujatha, S. Naganandini},
  booktitle={2015 IEEE International Conference on Computational Intelligence and Computing Research (ICCIC)}, 
  title={Rain drop detection and removal using K-Means clustering}, 
  year={2015},
  volume={},
  number={},
  pages={1-5},
  keywords={Rain;Clustering algorithms;Transforms;Algorithm design and analysis;Computational modeling;Lesions;Image segmentation;Image Clustering;Hough transforms;Median filters;Image segmentation;K-means Algorithm},
  doi={10.1109/ICCIC.2015.7435707}}

@inproceedings{eigen2013restoring,
  title={Restoring an image taken through a window covered with dirt or rain},
  author={Eigen, David and Krishnan, Dilip and Fergus, Rob},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={633--640},
  year={2013}
}

@inproceedings{qian2018attentive,
  title={Attentive generative adversarial network for raindrop removal from a single image},
  author={Qian, Rui and Tan, Robby T and Yang, Wenhan and Su, Jiajun and Liu, Jiaying},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2482--2491},
  year={2018}
}

@inproceedings{quan2021removing,
  title={Removing raindrops and rain streaks in one go},
  author={Quan, Ruijie and Yu, Xin and Liang, Yuanzhi and Yang, Yi},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9147--9156},
  year={2021}
}

@InProceedings{Parmeet_Report,
    author    = {Parmeet Madan Singh},
    title     = {Removing raindrops from images using deep learning},
    booktitle = {4th Year Project Report},
    month     = {May},
    year      = {2024},
    pages     = {}
}

@article{xu2012improved,
  title={An improved guidance image based method to remove rain and snow in a single image},
  author={Xu, Jing and Zhao, Wei and Liu, Peng and Tang, Xianglong},
  journal={Computer and Information Science},
  volume={5},
  number={3},
  pages={49},
  year={2012},
  publisher={Canadian Center of Science and Education}
}

@ARTICLE{6319316,
  author={He, Kaiming and Sun, Jian and Tang, Xiaoou},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Guided Image Filtering}, 
  year={2013},
  volume={35},
  number={6},
  pages={1397-1409},
  keywords={Image edge detection;Kernel;Smoothing methods;Joints;Histograms;Laplace equations;Jacobian matrices;Edge-preserving filtering;bilateral filter;linear time filtering},
  doi={10.1109/TPAMI.2012.213}}

@INPROCEEDINGS{Fu5946766,
  author={Fu, Yu-Hsiang and Kang, Li-Wei and Lin, Chia-Wen and Hsu, Chiou-Ting},
  booktitle={2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Single-frame-based rain removal via image decomposition}, 
  year={2011},
  volume={},
  number={},
  pages={1453-1456},
  keywords={Rain;Dictionaries;Image decomposition;Hafnium;Encoding;Training;Matching pursuit algorithms;Rain removal;sparse coding;dictionary learning;image decomposition;morphological component analysis (MCA)},
  doi={10.1109/ICASSP.2011.5946766}}

@inproceedings{MCA10.1117/12.615237,
author = {J.-L. Starck and Y. Moudden and J. Bobin and M. Elad and D. L. Donoho},
title = {{Morphological component analysis}},
volume = {5914},
booktitle = {Wavelets XI},
editor = {Manos Papadakis and Andrew F. Laine and Michael A. Unser},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {59140Q},
keywords = {Component Separation, inpainting, texture, ICA},
year = {2005},
doi = {10.1117/12.615237},
URL = {https://doi.org/10.1117/12.615237}
}

@INPROCEEDINGS{BilateralFiltering,
  author={Tomasi, C. and Manduchi, R.},
  booktitle={Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)}, 
  title={Bilateral filtering for gray and color images}, 
  year={1998},
  volume={},
  number={},
  pages={839-846},
  keywords={Filtering;Color;Low pass filters;Photometry;Imaging phantoms;Pixel;Shape measurement;Smoothing methods;Computer science;Humans},
  doi={10.1109/ICCV.1998.710815}}

@inproceedings{DictionaryLearningForSparseCoding,
author = {Mairal, Julien and Bach, Francis and Ponce, Jean and Sapiro, Guillermo},
title = {Online dictionary learning for sparse coding},
year = {2009},
isbn = {9781605585161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1553374.1553463},
doi = {10.1145/1553374.1553463},
abstract = {Sparse coding---that is, modelling data vectors as sparse linear combinations of basis elements---is widely used in machine learning, neuroscience, signal processing, and statistics. This paper focuses on learning the basis set, also called dictionary, to adapt it to specific data, an approach that has recently proven to be very effective for signal reconstruction and classification in the audio and image processing domains. This paper proposes a new online optimization algorithm for dictionary learning, based on stochastic approximations, which scales up gracefully to large datasets with millions of training samples. A proof of convergence is presented, along with experiments with natural images demonstrating that it leads to faster performance and better dictionaries than classical batch algorithms for both small and large datasets.},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
pages = {689–696},
numpages = {8},
location = {Montreal, Quebec, Canada},
series = {ICML '09}
}

@ARTICLE{SparseRepresentations,
  author={Fadili, M. Jalal and Starck, Jean-Luc and Bobin, Jérôme and Moudden, Yassir},
  journal={Proceedings of the IEEE}, 
  title={Image Decomposition and Separation Using Sparse Representations: An Overview}, 
  year={2010},
  volume={98},
  number={6},
  pages={983-994},
  keywords={Image decomposition;Source separation;Signal processing;Signal processing algorithms;Signal analysis;Iterative algorithms;Blind source separation;Application software;Software tools;Internet;Blind source separation;image decomposition;morphological component analysis;sparse representations},
  doi={10.1109/JPROC.2009.2024776}}

  @misc{ Curvelet,
    author = "{Wikipedia contributors}",
    title = "Curvelet --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=Curvelet&oldid=1258160544",
    note = "[Online; accessed 4-April-2025]"
  }

@ARTICLE{OMP,
  author={Mallat, S.G. and Zhifeng Zhang},
  journal={IEEE Transactions on Signal Processing}, 
  title={Matching pursuits with time-frequency dictionaries}, 
  year={1993},
  volume={41},
  number={12},
  pages={3397-3415},
  keywords={Matching pursuit algorithms;Time frequency analysis;Dictionaries;Pursuit algorithms;Fourier transforms;Signal representations;Vocabulary;Signal processing algorithms;Interference;Natural languages},
  doi={10.1109/78.258082}}

@INPROCEEDINGS{WuEtAl6467016,
  author={Wu, Qi and Zhang, Wende and Vijaya Kumar, B.V.K.},
  booktitle={2012 19th IEEE International Conference on Image Processing}, 
  title={Raindrop detection and removal using salient visual features}, 
  year={2012},
  volume={},
  number={},
  pages={941-944},
  keywords={Image color analysis;Automotive components;Rain;Shape;Cameras;Visualization;Roads;Intelligent vehicles;Saliency map;Image analysis;Object detection},
  doi={10.1109/ICIP.2012.6467016}}

  @misc{ SaliencyMapenwiki:1276598565,
    author = "{Wikipedia contributors}",
    title = "Saliency map --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2025",
    url = "https://en.wikipedia.org/w/index.php?title=Saliency_map&oldid=1276598565",
    note = "[Online; accessed 4-April-2025]"
  }

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

  @misc{ PSNRenwiki:1247121104,
    author = "{Wikipedia contributors}",
    title = "Peak signal-to-noise ratio --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/w/index.php?title=Peak_signal-to-noise_ratio&oldid=1247121104",
    note = "[Online; accessed 4-April-2025]"
  }

  @misc{ SSIMenwiki:1281587609,
    author = "{Wikipedia contributors}",
    title = "Structural similarity index measure --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2025",
    url = "https://en.wikipedia.org/w/index.php?title=Structural_similarity_index_measure&oldid=1281587609",
    note = "[Online; accessed 4-April-2025]"
  }

@inproceedings{quan2019deep,
  title={Deep learning for seeing through window with raindrops},
  author={Quan, Yuhui and Deng, Shijie and Chen, Yixin and Ji, Hui},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2463--2471},
  year={2019}
}

@inproceedings{nishigaki2012image,
  title={The image torque operator: A new tool for mid-level vision},
  author={Nishigaki, Morimichi and Ferm{\"u}ller, Cornelia and Dementhon, Daniel},
  booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition},
  pages={502--509},
  year={2012},
  organization={IEEE}
}


@Article{Kwon,
AUTHOR = {Kwon, Hyuk-Ju and Lee, Sung-Hak},
TITLE = {Raindrop-Removal Image Translation Using Target-Mask Network with Attention Module},
JOURNAL = {Mathematics},
VOLUME = {11},
YEAR = {2023},
NUMBER = {15},
ARTICLE-NUMBER = {3318},
URL = {https://www.mdpi.com/2227-7390/11/15/3318},
ISSN = {2227-7390},
ABSTRACT = {Image processing plays a crucial role in improving the performance of models in various fields such as autonomous driving, surveillance cameras, and multimedia. However, capturing ideal images under favorable lighting conditions is not always feasible, particularly in challenging weather conditions such as rain, fog, or snow, which can impede object recognition. This study aims to address this issue by focusing on generating clean images by restoring raindrop-deteriorated images. Our proposed model comprises a raindrop-mask network and a raindrop-removal network. The raindrop-mask network is based on U-Net architecture, which learns the location, shape, and brightness of raindrops. The rain-removal network is a generative adversarial network based on U-Net and comprises two attention modules: the raindrop-mask module and the residual convolution block module. These modules are employed to locate raindrop areas and restore the affected regions. Multiple loss functions are utilized to enhance model performance. The image-quality assessment metrics of proposed method, such as SSIM, PSNR, CEIQ, NIQE, FID, and LPIPS scores, are 0.832, 26.165, 3.351, 2.224, 20.837, and 0.059, respectively. Comparative evaluations against state-of-the-art models demonstrate the superiority of our proposed model based on qualitative and quantitative results.},
DOI = {10.3390/math11153318}
}

@inproceedings{woo2018cbam,
  title={Cbam: Convolutional block attention module},
  author={Woo, Sanghyun and Park, Jongchan and Lee, Joon-Young and Kweon, In So},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}

@InProceedings{U-Net,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}

@InProceedings{PatchGAN,
author = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A.},
title = {Image-To-Image Translation With Conditional Adversarial Networks},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {July},
year = {2017}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{fu2024uncertainty,
  title={Uncertainty-aware sparse transformer network for single image deraindrop},
  author={Fu, Bo and Jiang, Yunyun and Wang, Di and Gao, Jiaxin and Wang, Cong and Li, Ximing},
  journal={IEEE Transactions on Instrumentation and Measurement},
  year={2024},
  publisher={IEEE}
}

@misc{child2019generatinglongsequencessparse,
      title={Generating Long Sequences with Sparse Transformers}, 
      author={Rewon Child and Scott Gray and Alec Radford and Ilya Sutskever},
      year={2019},
      eprint={1904.10509},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1904.10509}, 
}

@misc{jin2024raindropclaritydualfocuseddataset,
      title={Raindrop Clarity: A Dual-Focused Dataset for Day and Night Raindrop Removal}, 
      author={Yeying Jin and Xin Li and Jiadong Wang and Yan Zhang and Malu Zhang},
      year={2024},
      eprint={2407.16957},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.16957}, 
}

@MISC{1975ieht.rept.....H,
       author = {{Hummel}, R.},
        title = "{Image enhancement by histogram transformation}",
     keywords = {Histograms, Imaging Techniques, Images, Pattern Recognition, Visual Perception, Optics},
         year = 1975,
        month = sep,
       adsurl = {https://ui.adsabs.harvard.edu/abs/1975ieht.rept.....H},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{scikit-image,
 title = {scikit-image: image processing in {P}ython},
 author = {van der Walt, {S}t\'efan and {S}ch\"onberger, {J}ohannes {L}. and
           {Nunez-Iglesias}, {J}uan and {B}oulogne, {F}ran\c{c}ois and {W}arner,
           {J}oshua {D}. and {Y}ager, {N}eil and {G}ouillart, {E}mmanuelle and
           {Y}u, {T}ony and the scikit-image contributors},
 year = {2014},
 month = {6},
 keywords = {Image processing, Reproducible research, Education,
             Visualization, Open source, Python, Scientific programming},
 volume = {2},
 pages = {e453},
 journal = {PeerJ},
 issn = {2167-8359},
 url = {https://doi.org/10.7717/peerj.453},
 doi = {10.7717/peerj.453}
}

@article{opencv_library,
    author = {Bradski, G.},
    citeulike-article-id = {2236121},
    journal = {Dr. Dobb's Journal of Software Tools},
    keywords = {bibtex-import},
    posted-at = {2008-01-15 19:21:54},
    priority = {4},
    title = {{The OpenCV Library}},
    year = {2000}
}

@ARTICLE{SSIM,
  author={Zhou Wang and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
  journal={IEEE Transactions on Image Processing}, 
  title={Image quality assessment: from error visibility to structural similarity}, 
  year={2004},
  volume={13},
  number={4},
  pages={600-612},
  keywords={Image quality;Humans;Transform coding;Visual system;Visual perception;Data mining;Layout;Quality assessment;Degradation;Indexes},
  doi={10.1109/TIP.2003.819861}}

@article{isola2017image,
  title={Image-to-image translation with conditional adversarial networks arXiv preprint},
  author={Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  journal={arXiv preprint arXiv:1703.06352},
  year={2017}
}

@inproceedings{woo2018cbam,
  title={Cbam: Convolutional block attention module},
  author={Woo, Sanghyun and Park, Jongchan and Lee, Joon-Young and Kweon, In So},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}

@article{simonyan2014vgg,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@article{stone1974cross,
  title={Cross-validatory choice and assessment of statistical predictions},
  author={Stone, Mervyn},
  journal={Journal of the royal statistical society: Series B (Methodological)},
  volume={36},
  number={2},
  pages={111--133},
  year={1974},
  publisher={Wiley Online Library}
}

@article{marcot2021optimal,
  title={What is an optimal value of k in k-fold cross-validation in discrete Bayesian network analysis?},
  author={Marcot, Bruce G and Hanea, Anca M},
  journal={Computational Statistics},
  volume={36},
  number={3},
  pages={2009--2031},
  year={2021},
  publisher={Springer}
}

@article{nti2021performance,
  title={Performance of machine learning algorithms with different K values in K-fold cross-validation},
  author={Nti, Isaac Kofi and Nyarko-Boateng, Owusu and Aning, Justice and others},
  journal={International Journal of Information Technology and Computer Science},
  volume={13},
  number={6},
  pages={61--71},
  year={2021},
  publisher={MECS Publisher}
}

@article{TANCHENKO2014874,
title = {Visual-PSNR measure of image quality},
journal = {Journal of Visual Communication and Image Representation},
volume = {25},
number = {5},
pages = {874-878},
year = {2014},
issn = {1047-3203},
doi = {https://doi.org/10.1016/j.jvcir.2014.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S1047320314000091},
author = {PSNRAlexander Tanchenko},
keywords = {Image quality, Objective measure of image quality, Peak signal-to-noise ratio, Block-based compression algorithm, Subjective image quality, Image database, Mean opinion score, Human visual system},
abstract = {Objective assessment of image quality is important in numerous image and video processing applications. Many objective measures of image quality have been developed for this purpose, of which peak signal-to-noise ratio PSNR is one of the simplest and commonly used. However, it sometimes does not match well with objective mean opinion scores (MOS). This paper presents a novel objective full-reference measure of image quality (VPSNR), which is a modified PSNR measure. It will be shown that VPSNR takes into account some features of the human visual system (HVS). The performance of VPSNR is validated using a data set of four image databases, and in this article it is shown that for images compressed by block-based compression algorithms (like JPEG) the proposed measure in the pixel domain matches well with MOS.}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@misc{long2015fullyconvolutionalnetworkssemantic,
      title={Fully Convolutional Networks for Semantic Segmentation}, 
      author={Jonathan Long and Evan Shelhamer and Trevor Darrell},
      year={2015},
      eprint={1411.4038},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1411.4038}, 
}

@misc{strudel2021segmentertransformersemanticsegmentation,
      title={Segmenter: Transformer for Semantic Segmentation}, 
      author={Robin Strudel and Ricardo Garcia and Ivan Laptev and Cordelia Schmid},
      year={2021},
      eprint={2105.05633},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2105.05633}, 
}


@inproceedings{SegFormer,
 author = {Xie, Enze and Wang, Wenhai and Yu, Zhiding and Anandkumar, Anima and Alvarez, Jose M. and Luo, Ping},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {12077--12090},
 publisher = {Curran Associates, Inc.},
 title = {SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers},
 url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/64f1f27bf1b4ec22924fd0acb550c235-Paper.pdf},
 volume = {34},
 year = {2021}
}


@inproceedings{wang2021pyramid,
  title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={568--578},
  year={2021}
}


@article{tarvainen2017mean,
  title={Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results},
  author={Tarvainen, Antti and Valpola, Harri},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@inbook{Perone_2018,
   title={Deep Semi-supervised Segmentation with Weight-Averaged Consistency Targets},
   ISBN={9783030008895},
   ISSN={1611-3349},
   url={http://dx.doi.org/10.1007/978-3-030-00889-5_2},
   DOI={10.1007/978-3-030-00889-5_2},
   booktitle={Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support},
   publisher={Springer International Publishing},
   author={Perone, Christian S. and Cohen-Adad, Julien},
   year={2018},
   pages={12–19} }


@inproceedings{yu2019uncertainty,
  title={Uncertainty-aware self-ensembling model for semi-supervised 3D left atrium segmentation},
  author={Yu, Lequan and Wang, Shujun and Li, Xiaomeng and Fu, Chi-Wing and Heng, Pheng-Ann},
  booktitle={Medical image computing and computer assisted intervention--MICCAI 2019: 22nd international conference, Shenzhen, China, October 13--17, 2019, proceedings, part II 22},
  pages={605--613},
  year={2019},
  organization={Springer}
}

@article{NGUYEN2022118232,
title = {UnfairGAN: An enhanced generative adversarial network for raindrop removal from a single image},
journal = {Expert Systems with Applications},
volume = {210},
pages = {118232},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.118232},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422013811},
author = {Duc Manh Nguyen and Thao Phuong Le and Duc My Vo and Sang-Woong Lee},
keywords = {Image deraining, Raindrop removal, Generative adversarial network, Deep Raindrops dataset},
abstract = {Image deraining is a new challenging problem in real-world applications, such as autonomous vehicles. In a bad weather condition of heavy rainfall, raindrops, mainly hitting glasses or windshields, can significantly reduce observation ability. Moreover, raindrops spreading over the glass can yield refraction’s physical effect, which seriously impedes the sightline or undermine machine learning systems. In this paper, we propose an enhanced generative adversarial network to deal with the challenging problems of raindrops. UnfairGAN is an enhanced generative adversarial network that can utilize prior high-level information, such as edges and rain estimation, to boost deraining performance. UnfairGAN can effectively conserve the essential details caused by heavy raindrops and remove artifacts caused by the instability of training the discriminator. This method is based on three main primary advantages. First, UnfairGAN consists of an advanced loss function of the discriminator that can improve the instabilities of traditional GAN. Second, UnfairGAN comprises a new advanced activation function that is able to increase the learning effectiveness of image classification and reconstruction. Finally, UnfairGAN is basically built on a new end-to-end cascade network, namely DRD-UNet, used to probe hierarchical features for image restoration effectively. When evaluating competing methods on the well-known Raindrop dataset, we achieve a peak signal-to-noise ratio value of 31.56 while retaining the essential details in the image. Besides, we introduce a new large image dataset (DeepRaindrops) for training deep learning networks of removing raindrops. In this dataset, our proposed method is superior to other state-of-the-art approaches of deraining raindrops regarding quantitative metrics and visual quality. Our source codes for UnfairGAN are available at https://github.com/ZeroZero19/UnfairGAN.git.}
}


@misc{jolicoeurmartineau2018relativisticdiscriminatorkeyelement,
      title={The relativistic discriminator: a key element missing from standard GAN}, 
      author={Alexia Jolicoeur-Martineau},
      year={2018},
      eprint={1807.00734},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1807.00734}, 
}


@inproceedings{liu2017richer,
  title={Richer convolutional features for edge detection},
  author={Liu, Yun and Cheng, Ming-Ming and Hu, Xiaowei and Wang, Kai and Bai, Xiang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3000--3009},
  year={2017}
}


@article{miyato2018spectral,
  title={Spectral normalization for generative adversarial networks},
  author={Miyato, Takeru and Kataoka, Toshiki and Koyama, Masanori and Yoshida, Yuichi},
  journal={arXiv preprint arXiv:1802.05957},
  year={2018}
}

@article{article,
author = {Brophy, Tim and Mullins, Darragh and Cormican, Robert and Ward, Enda and Glavin, Martin and Jones, Edward and Deegan, Brian},
year = {2025},
month = {01},
pages = {1-15},
title = {The Impact of Rain on Image Quality From Sensors on Connected and Autonomous Vehicles},
volume = {PP},
journal = {IEEE Open Journal of Vehicular Technology},
doi = {10.1109/OJVT.2025.3525853}
}


@article{jia2012two,
  title={A two-step approach to see-through bad weather for surveillance video quality enhancement},
  author={Jia, Zhen and Wang, Hongcheng and Caballero, Rodrigo E and Xiong, Ziyou and Zhao, Jianwei and Finn, Alan},
  journal={Machine Vision and Applications},
  volume={23},
  pages={1059--1082},
  year={2012},
  publisher={Springer}
}

@article{singh2012hawk,
  title={Hawk Eye: A Logical Innovative Technology Use in Sports for Effective Decision Making.},
  author={Singh Bal, Baljinder and Dureja, Gaurav},
  journal={Sport Science Review},
  volume={21},
  year={2012}
}

@article{Gao_2023,
   title={Large-Scale Unsupervised Semantic Segmentation},
   volume={45},
   ISSN={1939-3539},
   url={http://dx.doi.org/10.1109/TPAMI.2022.3218275},
   DOI={10.1109/tpami.2022.3218275},
   number={6},
   journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Gao, Shanghua and Li, Zhong-Yu and Yang, Ming-Hsuan and Cheng, Ming-Ming and Han, Junwei and Torr, Philip},
   year={2023},
   month=jun, pages={7457–7476} }
